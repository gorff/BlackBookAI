{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "GPU enabled\n"
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "  print(\"GPU enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our dataset\n",
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "\n",
    "zip_dir = tf.keras.utils.get_file(fname='./cats_and_dogs_filterted.zip', origin=_URL, extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n",
    "\n",
    "num_cats_tr = len(os.listdir(train_cats_dir))\n",
    "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
    "\n",
    "num_cats_val = len(os.listdir(validation_cats_dir))\n",
    "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
    "\n",
    "total_train = num_cats_tr + num_dogs_tr\n",
    "total_val = num_cats_val + num_dogs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Params\n",
    "BATCH_SIZE = 100\n",
    "IMG_SHAPE  = 150 # Our training data consists of images with width of 150 pixels and height of 150 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 2000 images belonging to 2 classes.\nFound 1000 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "# Data augmentation\n",
    "    # training - augmentation\n",
    "image_gen_train = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "train_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                     directory=train_dir,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_SHAPE,IMG_SHAPE),\n",
    "                                                     class_mode='binary')\n",
    "    # Validation - reshape\n",
    "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                 directory=validation_dir,\n",
    "                                                 target_size=(IMG_SHAPE, IMG_SHAPE),\n",
    "                                                 class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 148, 148, 32)      896       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n_________________________________________________________________\ndropout (Dropout)            (None, 7, 7, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 6272)              0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               3211776   \n_________________________________________________________________\ndense_1 (Dense)              (None, 2)                 1026      \n=================================================================\nTotal params: 3,453,634\nTrainable params: 3,453,634\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nTrain for 20 steps, validate for 10 steps\nEpoch 1/60\n20/20 [==============================] - 14s 718ms/step - loss: 0.6949 - accuracy: 0.5150 - val_loss: 0.6959 - val_accuracy: 0.5000\nEpoch 2/60\n20/20 [==============================] - 14s 719ms/step - loss: 0.6931 - accuracy: 0.5005 - val_loss: 0.6896 - val_accuracy: 0.5000\nEpoch 3/60\n20/20 [==============================] - 14s 723ms/step - loss: 0.6891 - accuracy: 0.5440 - val_loss: 0.6840 - val_accuracy: 0.5010\nEpoch 4/60\n20/20 [==============================] - 15s 736ms/step - loss: 0.6894 - accuracy: 0.5505 - val_loss: 0.6743 - val_accuracy: 0.5640\nEpoch 5/60\n20/20 [==============================] - 14s 715ms/step - loss: 0.6773 - accuracy: 0.5700 - val_loss: 0.6620 - val_accuracy: 0.6350\nEpoch 6/60\n20/20 [==============================] - 15s 729ms/step - loss: 0.6663 - accuracy: 0.6005 - val_loss: 0.6981 - val_accuracy: 0.5460\nEpoch 7/60\n20/20 [==============================] - 14s 719ms/step - loss: 0.6570 - accuracy: 0.6035 - val_loss: 0.6277 - val_accuracy: 0.6440\nEpoch 8/60\n20/20 [==============================] - 14s 718ms/step - loss: 0.6445 - accuracy: 0.6180 - val_loss: 0.6266 - val_accuracy: 0.6540\nEpoch 9/60\n20/20 [==============================] - 14s 720ms/step - loss: 0.6461 - accuracy: 0.6130 - val_loss: 0.6273 - val_accuracy: 0.6570\nEpoch 10/60\n20/20 [==============================] - 15s 726ms/step - loss: 0.6388 - accuracy: 0.6315 - val_loss: 0.6261 - val_accuracy: 0.6590\nEpoch 11/60\n20/20 [==============================] - 14s 724ms/step - loss: 0.6319 - accuracy: 0.6410 - val_loss: 0.6941 - val_accuracy: 0.5670\nEpoch 12/60\n20/20 [==============================] - 14s 722ms/step - loss: 0.6323 - accuracy: 0.6425 - val_loss: 0.6067 - val_accuracy: 0.6610\nEpoch 13/60\n20/20 [==============================] - 14s 722ms/step - loss: 0.6111 - accuracy: 0.6735 - val_loss: 0.6089 - val_accuracy: 0.6770\nEpoch 14/60\n20/20 [==============================] - 15s 725ms/step - loss: 0.6327 - accuracy: 0.6440 - val_loss: 0.6311 - val_accuracy: 0.6160\nEpoch 15/60\n20/20 [==============================] - 14s 717ms/step - loss: 0.6099 - accuracy: 0.6645 - val_loss: 0.6656 - val_accuracy: 0.6190\nEpoch 16/60\n20/20 [==============================] - 14s 716ms/step - loss: 0.6177 - accuracy: 0.6565 - val_loss: 0.5796 - val_accuracy: 0.7090\nEpoch 17/60\n20/20 [==============================] - 14s 721ms/step - loss: 0.5972 - accuracy: 0.6720 - val_loss: 0.5874 - val_accuracy: 0.6850\nEpoch 18/60\n20/20 [==============================] - 14s 713ms/step - loss: 0.6015 - accuracy: 0.6705 - val_loss: 0.5766 - val_accuracy: 0.7060\nEpoch 19/60\n20/20 [==============================] - 14s 715ms/step - loss: 0.6110 - accuracy: 0.6755 - val_loss: 0.5733 - val_accuracy: 0.7090\nEpoch 20/60\n20/20 [==============================] - 14s 714ms/step - loss: 0.6001 - accuracy: 0.6805 - val_loss: 0.5959 - val_accuracy: 0.6440\nEpoch 21/60\n20/20 [==============================] - 14s 723ms/step - loss: 0.5881 - accuracy: 0.6960 - val_loss: 0.5571 - val_accuracy: 0.7120\nEpoch 22/60\n20/20 [==============================] - 14s 720ms/step - loss: 0.5668 - accuracy: 0.7070 - val_loss: 0.5407 - val_accuracy: 0.7180\nEpoch 23/60\n20/20 [==============================] - 14s 711ms/step - loss: 0.5807 - accuracy: 0.6880 - val_loss: 0.5790 - val_accuracy: 0.7020\nEpoch 24/60\n20/20 [==============================] - 15s 725ms/step - loss: 0.5692 - accuracy: 0.7145 - val_loss: 0.5792 - val_accuracy: 0.7100\nEpoch 25/60\n20/20 [==============================] - 14s 713ms/step - loss: 0.5648 - accuracy: 0.7060 - val_loss: 0.6064 - val_accuracy: 0.6700\nEpoch 26/60\n20/20 [==============================] - 15s 728ms/step - loss: 0.5599 - accuracy: 0.7155 - val_loss: 0.5820 - val_accuracy: 0.6810\nEpoch 27/60\n20/20 [==============================] - 14s 720ms/step - loss: 0.5466 - accuracy: 0.7295 - val_loss: 0.5448 - val_accuracy: 0.7250\nEpoch 28/60\n20/20 [==============================] - 14s 717ms/step - loss: 0.5617 - accuracy: 0.7080 - val_loss: 0.5295 - val_accuracy: 0.7450\nEpoch 29/60\n20/20 [==============================] - 14s 712ms/step - loss: 0.5488 - accuracy: 0.7160 - val_loss: 0.5678 - val_accuracy: 0.6950\nEpoch 30/60\n20/20 [==============================] - 14s 712ms/step - loss: 0.5479 - accuracy: 0.7175 - val_loss: 0.5942 - val_accuracy: 0.6730\nEpoch 31/60\n20/20 [==============================] - 14s 716ms/step - loss: 0.5422 - accuracy: 0.7345 - val_loss: 0.5240 - val_accuracy: 0.7300\nEpoch 32/60\n20/20 [==============================] - 14s 723ms/step - loss: 0.5102 - accuracy: 0.7520 - val_loss: 0.5572 - val_accuracy: 0.7210\nEpoch 33/60\n20/20 [==============================] - 14s 713ms/step - loss: 0.5134 - accuracy: 0.7415 - val_loss: 0.5057 - val_accuracy: 0.7580\nEpoch 34/60\n20/20 [==============================] - 14s 716ms/step - loss: 0.5105 - accuracy: 0.7525 - val_loss: 0.5242 - val_accuracy: 0.7300\nEpoch 35/60\n20/20 [==============================] - 14s 714ms/step - loss: 0.5052 - accuracy: 0.7605 - val_loss: 0.4777 - val_accuracy: 0.7750\nEpoch 36/60\n20/20 [==============================] - 14s 710ms/step - loss: 0.5308 - accuracy: 0.7375 - val_loss: 0.5762 - val_accuracy: 0.6730\nEpoch 37/60\n20/20 [==============================] - 14s 712ms/step - loss: 0.5074 - accuracy: 0.7530 - val_loss: 0.4916 - val_accuracy: 0.7610\nEpoch 38/60\n20/20 [==============================] - 14s 707ms/step - loss: 0.5059 - accuracy: 0.7520 - val_loss: 0.4946 - val_accuracy: 0.7580\nEpoch 39/60\n20/20 [==============================] - 14s 710ms/step - loss: 0.4983 - accuracy: 0.7635 - val_loss: 0.4752 - val_accuracy: 0.7730\nEpoch 40/60\n20/20 [==============================] - 14s 712ms/step - loss: 0.4988 - accuracy: 0.7530 - val_loss: 0.5056 - val_accuracy: 0.7590\nEpoch 41/60\n20/20 [==============================] - 14s 709ms/step - loss: 0.4981 - accuracy: 0.7560 - val_loss: 0.4946 - val_accuracy: 0.7560\nEpoch 42/60\n20/20 [==============================] - 14s 711ms/step - loss: 0.4873 - accuracy: 0.7610 - val_loss: 0.4710 - val_accuracy: 0.7820\nEpoch 43/60\n20/20 [==============================] - 14s 709ms/step - loss: 0.4727 - accuracy: 0.7715 - val_loss: 0.5273 - val_accuracy: 0.7430\nEpoch 44/60\n20/20 [==============================] - 14s 711ms/step - loss: 0.4744 - accuracy: 0.7700 - val_loss: 0.4510 - val_accuracy: 0.7910\nEpoch 45/60\n20/20 [==============================] - 14s 711ms/step - loss: 0.4840 - accuracy: 0.7615 - val_loss: 0.4607 - val_accuracy: 0.7810\nEpoch 46/60\n20/20 [==============================] - 14s 715ms/step - loss: 0.4852 - accuracy: 0.7690 - val_loss: 0.4653 - val_accuracy: 0.7670\nEpoch 47/60\n20/20 [==============================] - 14s 712ms/step - loss: 0.4869 - accuracy: 0.7575 - val_loss: 0.4757 - val_accuracy: 0.7670\nEpoch 48/60\n20/20 [==============================] - 14s 712ms/step - loss: 0.4502 - accuracy: 0.7870 - val_loss: 0.5101 - val_accuracy: 0.7410\nEpoch 49/60\n20/20 [==============================] - 14s 722ms/step - loss: 0.4609 - accuracy: 0.7870 - val_loss: 0.4734 - val_accuracy: 0.7600\nEpoch 50/60\n20/20 [==============================] - 14s 712ms/step - loss: 0.4494 - accuracy: 0.7890 - val_loss: 0.4617 - val_accuracy: 0.7810\nEpoch 51/60\n20/20 [==============================] - 14s 719ms/step - loss: 0.4783 - accuracy: 0.7800 - val_loss: 0.4740 - val_accuracy: 0.7680\nEpoch 52/60\n20/20 [==============================] - 14s 723ms/step - loss: 0.4584 - accuracy: 0.7900 - val_loss: 0.4671 - val_accuracy: 0.7870\nEpoch 53/60\n20/20 [==============================] - 14s 711ms/step - loss: 0.4199 - accuracy: 0.8055 - val_loss: 0.4669 - val_accuracy: 0.7700\nEpoch 54/60\n20/20 [==============================] - 14s 717ms/step - loss: 0.4374 - accuracy: 0.8045 - val_loss: 0.4807 - val_accuracy: 0.7660\nEpoch 55/60\n20/20 [==============================] - 14s 722ms/step - loss: 0.4336 - accuracy: 0.8055 - val_loss: 0.4680 - val_accuracy: 0.7820\nEpoch 56/60\n20/20 [==============================] - 14s 719ms/step - loss: 0.4216 - accuracy: 0.8000 - val_loss: 0.4410 - val_accuracy: 0.7900\nEpoch 57/60\n20/20 [==============================] - 14s 709ms/step - loss: 0.4232 - accuracy: 0.8080 - val_loss: 0.4794 - val_accuracy: 0.7710\nEpoch 58/60\n20/20 [==============================] - 14s 723ms/step - loss: 0.4481 - accuracy: 0.7945 - val_loss: 0.4577 - val_accuracy: 0.7870\nEpoch 59/60\n20/20 [==============================] - 14s 712ms/step - loss: 0.4225 - accuracy: 0.8070 - val_loss: 0.4346 - val_accuracy: 0.7840\nEpoch 60/60\n20/20 [==============================] - 14s 716ms/step - loss: 0.4110 - accuracy: 0.8125 - val_loss: 0.4546 - val_accuracy: 0.7840\n"
    }
   ],
   "source": [
    "# Train\n",
    "epochs=60\n",
    "history = model.fit_generator(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model dir:  models\\catsAndDogs\\1\n"
    }
   ],
   "source": [
    "# Define a destination path for the model\n",
    "MODEL_EXPORT_DIR = os.path.join('models','catsAndDogs')\n",
    "MODEL_VERSION = 2\n",
    "MODEL_EXPORT_PATH = os.path.join(MODEL_EXPORT_DIR, str(MODEL_VERSION))\n",
    "print(\"Model dir: \", MODEL_EXPORT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Assets written to: models\\catsAndDogs\\1\\assets\n"
    }
   ],
   "source": [
    "model.reset_metrics()\n",
    "# Export the model to a SavedModel\n",
    "model.save(MODEL_EXPORT_PATH, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}